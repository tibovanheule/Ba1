\title{Samenvatting Algoritmen en Datastructuren}
\author{
	{\bf Lesgever:} Prof. dr. Veerle Fack \\
	{\bf Auteur(s):} Manu De Buck \\
	{\bf Laatste bewerking:} \\
	{\bf Bibliografie:} Algoritmen en Datastructuren, Veerle Fack, acco
	}


\documentclass[12pt]{report}
\usepackage{makeidx}
\usepackage{textcomp}
\usepackage{titlesec}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fullpage}


\makeindex

\begin{document}
\maketitle

\chapter{Inleiding}

\section{Algoritmen}
{\bf Functie:} Koppeling tussen inputs ({\bf het domein}) en outputs ({\bf het bereik}).\\\
{\bf Parameters:} Waarden waaruit de input bestaat. \\
\textrightarrow Zelfde input genereert {\bf altijd} zelfde output.\\\
 {\bf Algoritmisch probleem:} Eindige of oneindige verzameling toegelaten inputwaarden, samen met een specificatie van de gewenste output als functie van de input, noemt met een algoritmisch probleem. Als er ten minste één oplossingsmethode bestaat die voor elke legale input de gewenste output voorbrengt.\\\
 {\bf Algoritme:} is een methode die wordt gevolgd om een algoritmisch probleem op te lossen.\\\
 \begin{enumerate}
 \item Algoritme moet correct zijn
 \item Bestaat uit concreet aantal stappen. Elke stap uitvoerbaar in eindige hoeveelheid tijd.
 \item Geen dubbelzinnigheid betreffende de stappen.
 \item Bestaat uit eindig aantal stappen.
 \item Het algoritme moet eindigen.
 \end{enumerate}
 
 \section{Ontwerp en specificatie van algoritmen}
 {\bf Pseudocode:} Mengeling van natuurlijke taal en constructies uit een programmeertaal.\\
 \textrightarrow Input, beschrijving output en reeks pseudocodeopdrachten die algoritme weergeven.\\\
 
 \section{Correctheid van algoritmen}
  {\bf Formele wiskundige bewijstechnieken} om de correctheid van een algoritme aan te tonen.\\\
  Indien bewijs niet gevonden wordt: beroep doen op  {\bf het uitvoeren van testen}.
  
 \subsection{Bewijzen door contradictie}
  Geven van een tegenvoorbeeld voor de bewering, maar volstaat niet om te bewijzen dat bewering waar is.\\\
  Wel correct:  {\bf bewijzen door contradictie:} veronderstellen dat bewering niet waar is, daaruit tegenstrijdigheid afleiden.\\\
  
  \subsection{Bewijzen door inductie}
  Bewijzen dat een reeks beweringen X\textsubscript{1}, X\textsubscript{2}, ..., X\textsubscript{n} waar is, door eerst te bewijzen dat X\textsubscript{1} waar is en vervolgens te veronderstellen dat X\textsubscript{i} waar is (inductiehypothese) en te bewijzen dat X\textsubscript{i+1} waar is (inductiestap).\\\
  Eenvoudige vorm inductie vs. {\bf sterke wiskundige inductie}\\\
  Uit het ene volgt het volgende vs. We nemen aan dat alles voorafgaand aan X\textsubscript{j} voor j = 1, ..., i waar is.\\\
  
  \subsection{Bewijzen met lusvarianten}
  {\bf Lusvariante:} is eenbewering over variabelen die waar is vooraleer de lus uitgevoerd word en die ook waar is na elke iteratiestap in de lus.\\\
  
  \section{Effici\"{e}ntie van algoritmen}
  
  \subsection{Analyse van algoritmen}
  Belang voor het nagaan van complexiteit van algoritme in ruimte en tijd. Een {\bf schatting} maken van de {\bf benodigde geheugenruimte} en de {\bf uitvoeringstijd}.\\\
  Een algortime is {\bf effici\"{e}nt} als het het gestelde probleem oplost binnen de vooropgestelde beperkingen qua resources. De {\bf kost} van een oplossing is de hoeveelheid resources die de oplossing verbruikt.\\\
  {\bf complexiteitsanalyse }van de algoritmen laat toe ze {\bf onderling te vergelijken} en afhankelijk daarvan de effici\"{e}ntste te selecteren.\\\
  Twee doelstellingen bij oplossen probleem:
  \begin{enumerate}
  \item Algoritme ontwerpen dat eenvoudig te begrijpen, coderen en debuggen is.
  \item Algoritme ontwerpen dat de beschikbare resources effici\"{e}nt gebruikt.
  \end{enumerate}
  Zie hoofdstuk 2 voor {\bf asymptotische analyse}.
  
  \subsection{Snelle schattingen}
  Maken van een snelle schatting:
  \begin{enumerate}
  \item Bepaal de belangrijke factoren die het probleem be\"{i}nvloeden.
  \item Stel een vergelijking op die de parameters van het probleem met elkaar verbindt.
  \item Selecteer waarden voor de parameters, en gebruik de bekomen vergelijking om een geschatte oplossing te bekomen.
  \end{enumerate}
  
\section{Datastructuren}
{\bf Datastructuur:} een voorstelling van gegevens en de bijbehorende bewerkingen op die gegevens. \\\
Selecteren datastructuur:
\begin{enumerate}
\item Analyseer het probleem om te bepalen welke vereisten qua resources elke oplossing moet voldoen.
\item Bepaal de basisbewerkingen die moeten worden ondersteund, en de vereisten waaraan ze moeten voldoen. Voorbeelden van basisbewerkingen zijn het toevoegen van een element aan de datastructuur, het verwijderen van een element uit de datastructuur en het opzoeken van een gegeven element.
\item Selecteer de datastructuur die het best aan deze vereisten voldoet.
\end{enumerate}
Vereisten op bepaalde sleutelbewerkingen:
\begin{enumerate}
\item Worden alle gegevens aan de datastructuur toegevoegd vooraleer de andere bewerkingen (zoals opzoekingen) gebeuren of zijn toevoegingen afgewisseld met andere bewerkingen?
\item Kunnen elementen verwijderd worden?
\item Worden de elementen verwerkt in een specifieke volgorde of is willekeurige toegang mogelijk?
\end{enumerate}
{\bf Abstract datatype:} Een abstracte specificatie van een datastructuur die de formele beschrijving van een data-object evenals een beschrijving van de bewerkingen die op de structuur kunnen worden uitgevoerd. {\bf (ADT)}.\\\
Door abstractie te maken van het type van de componenten en meer in het bijzonder dit type als een parameter te behandelen, specificeert men een {\bf generische datastructuur}.

\chapter{Analyse van algoritmen}

\section{Complexiteit van algoritmen}

\subsection{Inleiding}
{\bf Asymptotische analyse} van het algoritme: meet de effici\"{e}ntie van een algoritme, of zijn implementatie als een computerprogramma wanneer zijn inputgrootte groot wordt. Het is een schattingstechniek, die niets zegt over de relatieve verdiensten van twee programma's waarbij het ene net iets sneller is dan het andere.\\\
Analyse bestaat typisch uit:
\begin{enumerate}
\item Inschatten nodige {\bf uitvoeringstijd}
\item Inschatten benodigde {\bf geheugenruimte} voor een {\bf datatsructuur}
\end{enumerate}

\subsection{Theoretisch model}
{\bf Inputgrootte:} het aantal inputgegevens dat verwerkt wordt.\\\
De inputgegevens vormen vaak maat  voor de omvang of {\bf complexiteit} van een probleem.\\\
Uitvoeringstijd van een algoritme is een functie van de grootte van de input.\\\
Voor {\bf theoretische analyse:} uitvoeringstijd uitdrukken als aantal basisbewerkingen uitgevoerd bij de oplossing van het probleem.\\\
{\bf Basisbewerking:} zijn uitvoeringstijd is niet afhankelijk van specifieke waarden van operanden.\\\
\paragraph{Notatie:} voor een inputgrootte {\it n} noteren we de uitvoeringstijd {\it T} van het algoritme als een functie van {\it n} dus als {\it T(n)}. Hierbij veronderstellen we dat {\it T(n)} een niet-negatieve waarde heeft.

\subsection{Functies voor de uitvoeringstijd}
{\bf Orde van toename} van een functie, is de mate waarin de functie stijgt voor toenemende waarden van {\it n}.\\\
Voorbeelden:
\begin{enumerate}
\item Lineair ({\it n})
\item {\it n}log{\it n}
\item Kwadratisch ({\it n\textsuperscript{2}})
\item Kubisch ({\it n\textsuperscript{3}})
\item Exponentieel ({\it a\textsuperscript{n},  a \(\in\) ${\rm I\!R}$})
\end{enumerate}

\subsection{Asymptotische analyse}
Orde van toename, verwaarloost de constanten en lagere-ordetermen. Dit vereenvoudigt de analyse. 
\paragraph{Notatie} De {\bf \(\Theta\)-notatie} stelt de orde van toename als functie voor.\\\ 
{\it Bijvoorbeeld, \( T(n) = 5n + 3\), dan is de uitvoerinstijd \(T(n) = \Theta (n)\).}\\\
Dit laat toe de relatieve performantie van algoritmen te vergelijken.
\paragraph{} Dergelijke analyse noemen we {\bf asymptotische analyse van een algoritme}.

\subsection{Gemiddelde, beste en slechtste uitvoeringstijd}
\paragraph{}Voor een gegeven algoritme kunnen we een onderscheid maken tussen {\it T\textsubscript{g}(n), T\textsubscript{s}(n), T\textsubscript{b}(n)} - respectievelijk de {\bf gemiddelde uitvoeringstijd}, de {\bf slechtst mogelijke uitvoeringstijd} en de {\bf best mogelijke uitvoeringstijd} van het algoritme als functie van de probleemgrootte {\it n}. Vanzelfsprekend geldt er:  {\it  T\textsubscript{b}(n) \(\leq\) T\textsubscript{g}(n) \(\leq\) T\textsubscript{s}(n)}.

\section{Asymptotische notaties}

\subsection{Definities}
Zijn gedefinieerd om asymptotische gedrag van twee gegeven functies {\it f en g} gedefinieerd op $\mathbb{N}$, waarbij verondersteld wordt dat {\it f en g asymptotische niet-negatieve functies zijn.}

\subsubsection{Bovengranzen en \(O\)-notatie}
Bovengrens geeft aan wat hoogste orde van toename is dat algoritme kan hebben.\\\
Merk op: niet hetzelfde als slechtst mogelijke uitvoeringstijd voor een gegeven input van grootte n.\\\
"Heeft een bovengrens voor zijn orde van toename van {\it f(n)}" : de \(O\)-notatie.\\\
\paragraph{Definitie 2.2.1.} {\it f(n) = \(O\)(g(n)) indien er constanten c \(\in \) $\mathbb{R}_{>0}^{+}$ en n\textsubscript{0}  \(\in\) $\mathbb{N}$ bestaan, zodanig dat \(0 \leq f(n) \leq cg(n)\) voor alle \(n \geq n\textsubscript{0}\)}
\paragraph{} Men zegt: {\bf f(n) wordt asymptotisch naar boven toe begrensd door g(n)}.

\subsubsection{Ondergrenzen en \(\Omega\)-notatie}
\paragraph{}Ondergrens van een algoritme wordt genoteerd door de \(\Omega\)-notatie.
\paragraph{Definitie 2.2.2.} {\it \(f(n) = \Omega (g(n))\) indien er constanten \(c \in \) $\mathbb{R}_{>0}^{+}$ en n\textsubscript{0} \(\in\) $\mathbb{N}$  bestaan, zodanig dat \(f(n) \geq cg(n) \geq 0\) voor alle \(n \geq \) n\textsubscript{0}}
\paragraph{} Men zegt dat {\bf asymptotisch naar onder toe begrensd wordt door g}.
\paragraph{} Merk op:  f(n) = \(O\)(g(n)) a.s.a \(g(n) = \Omega (f(n))\)

\subsubsection{\(\Theta\)-notatie}
\paragraph{}Als bovengrens en ondergrens gelijk zijn op een constante factor na: uitdrukken door \(\Theta\)-notatie.
\paragraph{Definitie 2.2.3.}{\it \(f(n) = \Theta (g(n))\) a.s.a \(f(n) = O(g(n))\) en \(f(n) = \Omega (g(n))\), m.a.w. indien er constanten c\textsubscript{1}, c\textsubscript{2} \(\in\) $\mathbb{R}_{>0}^{+}$ en n\textsubscript{0} \(\in\) $\mathbb{N}$ bestaan, zodanig dat \(0 \leq c\)\textsubscript{1}\(g(n) \leq f(n) \leq c\textsubscript{2}g(n)\) voor alle n \(\geq\) n\textsubscript{0}.}
\paragraph{}Men zegt dat f en g op een positieve constante na, {\bf hetzelfde gedrag op oneindig} vertonen. Merk op dat de volgende symmetrie-eigenschap nu geldig is: \(f(n) = \Theta (g(n))\) a.s.a. \(g(n) = \Theta (f(n))\)

\subsubsection{\(o\)- en \(\omega\)-notatie}
\paragraph{} voor het specificeren van strikte boven en ondergrenzen op de orde van toename.
\paragraph{Definitie 2.2.4.} {\it \(f(n) = o(g(n))\) a.s.a. \(f(n) = O(g(n))\) en \(f(n) \neq \Theta (g(n))\).}
\paragraph{Definitie 2.2.5.}{\it  \(f(n) = \omega(g(n))\) a.s.a. \(f(n) = \Omega (g(n))\) en \(f(n) \neq \Theta (g(n))\).}

\subsection{Werken met asymptotische notaties}

\subsubsection{De limietregel}
Vergelijken door lim\textsubscript{n \(\to \infty\)} f(n) / g(n) (evt. regel van de l'H\^{o}pital.
\begin{enumerate}
\item De limiet is 0: \(f(n) = 0(g(n))\) en \(f(n) \neq \Theta (g(n))\), of dus \(f(n) = o(g(n))\).
\item De limiet is een constante c \(\neq\) 0: \(f(n) = \Theta (g(n))\).
\item De limiet is \( + \infty\): \(f(n) = \Omega (g(n))\) en \(f(n) \neq \Theta (g(n))\), of dus \(f(n) = \omega (g(n))\).
\item De limiet bestaat niet: dan moet een eventueel ordeverband tussen f(n) en g(n) op een andere manier worden bepaald.
\end{enumerate}

\subsubsection{Vereenvoudigingsregels}
\begin{enumerate}
\item Als \(f(n) = \Theta (g(n))\) en \(g(n) = \Theta (h(n))\), dan \(f(n) = \Theta (h(n))\). \\ Als een functie g(n) een maat geeft voor de orde van toename van de kostfunctie f(n), dan geeft elke functie h(n) die een maat geeft voor de orde van toename van g(n) ook een maat voor de orde van toename van f(n).
\item Als \(f\textsubscript{1}(n) = \Theta (g\textsubscript{1}(n))\) en \(f\textsubscript{2}(n) = \Theta (g\textsubscript{2}(n))\), dan \(f\textsubscript{1}(n) + f\textsubscript{2}(n) = \Theta (max(g\textsubscript{1}(n), g\textsubscript{2}(n)))\). \\ Van twee gedeelten van een algoritme die na elkaar worden uitgevoerd moeten we enkel het duurste gedeelte beschouwen.
\item Als \(f\textsubscript{1}(n) = \Theta (g\textsubscript{1}(n))\) en \(f\textsubscript{2}(n) = \Theta (g\textsubscript{2}(n))\), dan \(f\textsubscript{1}(n) f\textsubscript{2}(n) = \Theta (g\textsubscript{1}(n) g\textsubscript{2}(n))\). \\ Als een bepaalde actie een aantal keren herhaald wordt en elke herhaling dezelfde kost heeft, dan is de totale kost gegeven door de kost van de actie vermenigvuldigd met het aantal herhalingen. Deze regel is nuttig bij het analyseren van eenvoudige lussen in algoritmen.
\end{enumerate}
\paragraph{} Analoge regels zijn geldig voor \(O\)- en \(\Omega\)-notatie
 
\subsection{Asymptotisch gedrag van standaarfuncties}
\paragraph{Stelling 2.2.6} 
\begin{enumerate} {\it 
\item Als T(n) een veelterm in n van graad d is, dan is T(n) = \(\Theta\)\((n^d)\).
\item \(n^b = o(a^n)\), voor alle re\"{e}le constanten a en b, met a \(>\) 1.
\item \((log_{c}n)^b = o(n^a)\), voor alle re\"{e}le constanten a, b, c met a, c \(>\) 0.
}
\end{enumerate}
\paragraph{}Verwisselen tussen basissen van logaritmen gaat met behulp van volgende formule: \(log_{a}x = \frac{log_{c}x}{log_{c}a}\), met c \(>\) 0.
\paragraph{Stelling 2.2.7} {\it De Fibonacci-getallen, gedefinieerd als \(F_0 = 0, F_1 = 1, F_n = F_{n-1} + F_{n-1}\) voor n \(>\) 1, vormen een exponentieel stijgende functie.}\\ \newline
{\it Bewijs.} De volgende eigenschap geldt voor de Fibonacci-getallen \(F_i = (\phi ^i - \phi_-^i) /\sqrt{5}\), met \(\phi = (1 + \sqrt{5})/2 = 1.61...\) en \(\phi_- = (1 - \sqrt{5})/2 = - 0.61...\). Aangezien \(|\phi_-| < 1\), geldt dat \(|  \phi_-^i | /\sqrt{5} < 1/2 \), zodat geldt dat \( F_i = round(\phi^i / \sqrt{5})\). 
\paragraph{Stelling 2.2.8} {\it De faculteitsfunctie is snelstijgend, met volgende eigenschappen:\\
\begin{enumerate}
\item n! = \(o(n^n)\),
\item n! = \(\omega (2^n)\),
\item \(log_2(n!) = \Theta(nlogn)\).
\end{enumerate}
Bewijs.}
We bewijzen enkel eigenschap 3. Daartoe bewijzen we eerst een bovengrens:\\\
\begin{equation}
\begin{split}
log_2(n!) & = log_2n + log_2(n-1) + ... + log_21\\
 & =  \leq log_2n + log_2n + ... + log_2n\\
 & = nlog_2n
\end{split}
\end{equation}
Hieruit volgt dat \(log_2(n!) = O(nlogn)\). Vervolgens bewijzen we een ondergrens:
\begin{equation}
\begin{split}
log_2(n!) & = log_én + log_2(n-1) + ... + log_21 \\
& \geq log_2n + log_2(n-1) + ... + log_2( \lceil n/2 \rceil)\\
& \geq log_2(\lceil n/2 \rceil ) + log_2(\lceil n/2 \rceil ) + ... + log_2(\lceil n/2 \rceil )\\
& = \lceil (n + 1)/2 \rceil * log_2(\lceil n/2 \rceil ) \\
& \geq (n/2) log_2(n/2)\\
& = (n/2) log_2( n - n/2)\\
& \geq (nlog_2n)/4,  n \geq 4
\end{split}
\end{equation}
Hieruit volgt dat \(log_2(n!) = \Omega(nlogn)\). Dus hebben we bewezen dat \(log_2(n!) = \Theta (nlogn)\)

\section{Bepalen van tijds- en geheugencomplexiteit}
\subsection{Het tijd/ruimte-tradeoff-principe}
\paragraph{}Dit principe zegt ons dat in vele gevallen een reductie in uitvoeringstijd allen kan worden bekomen als men bereid is om geheugenruimte op te offeren, en vice versa.
 
 \section{Praktische beschouwingen}
 
 \section{Geamortiseerde complexiteitsanalyse}
\paragraph{}Beschouwt de kost van een ganse sequentie van m bewerkingen , en kent aan iedere individuele bewerking een gedeelte van de totale kost toe. Men noemt dit de {\bf geamortiseerde kost} van de bewerking. Indien we voor een bewerking kunnen aantonen dat het slechtste geval niet herhaaldelijk kan voorkomen, kunnen we een betere begrenzing voor de totale tijd bekomen en kunnen we de bewerkingen beschouwen alsof ze uitgemiddelde begrenzing van deze totale begrenzing heeft. We noemen dit een {\bf geamortiseerde tijdsbegrenzing}.

\section{Handelbare en onhandelbare problemen}
\paragraph{Handelbaar} Een computationeel probleem wordt handelbaar genoemd als er een polynomiaal\footnote{ Als de benodigde tijd, als functie van n, begrensd wordt door een polynoom} algoritme bestaat om het probleem op te lossen; de betekenis hiervan is dat er dan een effici\"ent algoritme voor het probleem bestaat.
\paragraph{Onhandelbaar} Een computationeel probleem wordt onhandelbaar genoemd als kan worden bewezen dat er geen polynomiaal algoritme is om het probleem op te lossen.
\paragraph{NP-complete} De meeste van deze onhandelbare problemen behoren tot de klasse van NP-complete problemen. (De klasse NPC). Hiervan is wel reeds bewezen dat, als er voor één van de problemen uit de klasse NPC een polynomiaal algoritme bestaat, er dan ook voor alle andere problemen uit de klasse NPC een polynomiaal algoritme bestaat.
\paragraph{Beslissingsprobleem} Een beslissingsprobleem is een probleem dat enkel een antwoord "ja" of "nee" vereist, afhankelijk van het feit of de input een bepaalde eigenschap heeft. Zo'n probleem behoort tot de {\bf klasse} P als er een polynomiaal algoritme bestaat om het probleem op te lossen. Anders behoort het tot de {\bf klasse NP\footnote{Niet-deterministisch polynomiaal.}} als er een manier is om de correctheid van een "ja"-antwoord in polynomiale tijd te verifi\"eren.
\paragraph{Polynomiaal herleidbaar} Een beslissingsprobleem R is polynomiaal herleidbaar tot Q als er een transformatie in polynomiale tijd bestaat van elke instantie \(I_R\) van probleem R naar een instantie \(I_Q\) van probleem Q, zodanig dat de instanties \(I_R\) en \(I_Q\) hetzelfde antwoord ("ja" of "nee") hebben.
\paragraph{NP-moeilijk} Een beslissingsprobleem is NP-moeilijk als elk probleem in de klasse NP polynomiaal herleidbaar is tot R.
\paragraph{NP-compleet} Een NP-moeilijk beslissingsprobleem R is NP-compleet als R tot de klasse NP behoort. De klasse van NP-complete problemen wordt ook de klasse NPC genoemd.

\chapter{Gebruik van stapels en (prioriteitswachtlijnen)}

\section{Stapels en compilers}
\paragraph{Stapel} Een stapel is een collectie-datatsructuur waarbij geldt dat het element dat het laatst werd toegevoegd, het eerst weer wordt opgehaald. Dit principe wordt ook wel LIFO (Last In First Out) genoemd.

\section{Simulatie en prioriteitswachtlijnen}
\paragraph{Prioriteitswachtlijnen} Op bepaalde punten moet de volgende gebeurtenis in een collectie van gebeurtenissen worden bepaald, of een gebeurtenis op de juiste manier aan de collectie worden toegevoegd zodat deze op het juiste moment als volgende gebeurtenis aanzien kan worden. Hiervoor gebruikten we een prioriteitswachtlijn.
\paragraph{Discrete tijdsgestuurde simulatie} Dit is een simulatie waarbij bij het begin van de simulatie de simulatieklok op nul gezet wordt, en vervolgens wordt de klik telkens \'e\'en tik vooruit gezet en gecontroleerd of een gebeurtenis optreedt of niet.
\paragraph{Gebeurtenisgestuurde simulatie} Dit is een simulatie waarbij de simulatieklok telkens vooruit geplaatst wordt naar de volgende gebeurtenis. Dit is conceptueel makkelijker te verwezenlijken.

\chapter{Recursie}

\section{Ontwerp van recursieve algoritmen}
\paragraph{Recursief} Een algoritme is recursief als het zichzelf oproept om een gedeelte van het werk uit te voeren. Opdat dit succesvol zou zijn, moet de oproep naar zichzelf een kleiner probleem dan het oorspronkelijke probleem betreffen.
\paragraph{Complexiteitsanalyse} Dit verloopt vaak moeilijker, aangezien deze dikwijls beschreven worden door een {\bf recurrente betrekking} die moet worden opgelost.

\section{Analyse van recursieve algoritmen}
\paragraph{Recurrente betrekking} De uitvoeringstijd wordt doorgaans beschreven door een recurrente betrekking die moet worden opgelost. We beperken ons tot het bepalen van asymptotische \(\Theta\)- of \(O\)-grenzen voor de oplossing.

\subsection{Iteratiemethode}
\paragraph{} De betrekking wordt iteratief volledig uitgewerkt tot een sommatie waarin enkel n en de initiële waarden optreden.

\subsection{Substitutiemethode}
\paragraph{} Oplossing voor recurrente betrekking wordt vooropgesteld, en vervolgens wordt m.b.v. wiskundige inductie bewezen dat deze oplossing werkt.

\subsection{Recursiebomen}
\paragraph{Recursieboom} dit is een handig hulpmiddel om te visualiseren wat er precies gebeurt bij het uitwerken van een iteratie voor een recurrente betrekking.

\subsection{Master-methode}
\paragraph{} Deze methode geeft een recept voor het oplossen van recurrente betrekkingen van ed vorm \(T(n) = aT(n/b) + f(n)\).
\paragraph{Stelling 5.2.1, master-stelling} {\it Zij \(a \geq 1\) en \(b > 1\) constanten, zij f(n) een asymptotische positieve functie, en zij \(T(n)\) gedefinieerd door de recurrente betrekking \(T(n) = aT(n/b) + f(n)\)}.
\begin{enumerate}
\item Als f(n) = \(O(n^{log_ba-\varepsilon})\) voor zekere constante \(\varepsilon > 0\), dan is \(T(n) = \Theta (n^{log_ba})\).
\item Als f(n) = \(\Theta (n^{log_ba})\), dan is \(T(n) = \Theta(n^{log_ba}logn)\).
\item Als f(n) = \(\Omega (n^{log_ba+\varepsilon})\) voor zekere constante  \(\varepsilon > 0\), en als \(af(n/b) \leq cf(n)\) voor zekere constante \(c < 1\) en voldoende grote n (d.i. regulariteitsvoowaarde), dan is \(T(n) = \Theta(f(n))\)
\end{enumerate}

\section{Wanneer recursie af te raden is}

\subsection{Staartrecursie}
\paragraph{Staartrecursie} Over het algemeen geldt dat recursie wordt afgeraden (wegens overhead) als het kan vervangen worden door een simpele lus. We noemen dit staartrecursie (De recursieve versie).

\chapter{Verdeel-en-heers-algoritmen}

\section{Ontwerpstrategie\"en voor algoritmen}
\subsubsection{Brute kracht (brute force)}
\paragraph{De brute-kracht-methode} lost een probleem op door alle mogelijkheden uit te proberen. Zeer ineffici\"ent.

\subsubsection{Tijd/ruimte-tradeoffs}
\paragraph{} Gebruiken van extra geheugenruimte om uitvoeringstijd te reduceren. Een voorbeeld hiervan is de frequentietabel.

\subsubsection{Verdeel-en-heers (Divide-and-conquer)}
\paragraph{} Algoritmen volgens deze strategie bestaan uit twee gedeelten:
\begin{enumerate}
\item {\bf Verdeel-fase}, oorspronkelijke probleem wordt opgesplitst in kleinere deelproblemen die recursief worden opgelost.
\item {\bf Heers-fase}, waarbij oplossing voor het oorspronkelijke probleem wordt geconstrueerd uit de oplossingen van de deelproblemen.
\end{enumerate}
\paragraph{}De bekomen deelproblemen moeten disjunct zijn opdat deze methode effici\"ent zouden zijn.

\subsubsection{Verminder-en-heers (Decrease-and-conquer)}
\paragraph{Variant op verdeel-en-heers,} genaamd verminder-en-heers, hierbij wordt de oplossing van een probleem bepaald door slechts \'e\'en gelijkaardig deelprobleem. Dikwijls hebben we hierbij te maken met een geval van staartrecursie. Er zijn hierop drie mogelijke variaties:
\begin{enumerate}
\item {\bf Verminder met een constante}. De probleemgrootte wordt in elke stap verminderd met constante waarde.
\item {\bf Verminder met een constante factor}. Probleemgrootte wordt in elke stap gedeeld door een constante factor, typisch 2.
\item {\bf Verminder met een variabele grootte}. Probleemgrootte in elke stap verkleinen met of gedeeld door een waarde die kan vari\"eren in de verschillende stappen.
\end{enumerate}

\subsubsection{Transformeer-en-heers (Transform-and-conquer)}
\paragraph{} Transformeren van oorspronkelijk probleem naar een ander probleem. Drie variaties van de techniek:
\begin{enumerate}
\item {\bf Vereenvoudiging van het probleem}. Het probleem wordt getransformeerd naar een eenvoudiger of meer geschikte variant van hetzelfde probleem. Bijvoorbeeld: input probleem vooraf sorteren.
\item {\bf Verandering van voorstelling}. Veranderen naar een andere representatie van het probleem.
\item {\bf Reductie van het probleem}. Het probleem wordt getransformeerd naar een ander probleem waarvoor reeds een algoritme gekend is. Bijvoorbeeld: de klassieke problemen uit de grafentheorie.
\end{enumerate}

\section{Zoeken in rijen}
\paragraph{} In een gesorteerde rij kan sneller gezocht worden met behulp van de {\bf binaire zoekmethode.}

\subsection{Het sequenti\"ele zoekalgoritme}
\paragraph{}Eenvoudige oplossing overloopt een voor een de objecten en vergelijkt ze met het gezochte element. Dit wordt herhaald totdat het element gevonden is, of totdat de gehele rij overlopen is.
\paragraph{Sentinel of 'schildwacht'} Dit voorkomt de nood aan twee te controleren condities bij een lus over een rij. Het gezochte element wordt achteraan de lijst toegevoegd zodat het element zeker gevonden wordt.
\paragraph{}Bij een gesorteerde rij kunnen hieraan enkele verbeteringen worden aangebracht. Het kan bijvoorbeeld worden stopgezet wanneer een element bereikt is dat groter is dan het te zoeken element.
\paragraph{}Bij het sequenti\"ele zoeken is de slechtste uitvoeringstijd \(\Theta(n)\)

\subsection{De binaire zoekmethode}
\paragraph{}We kunnen een willekeurig element nemen uit een gesorteerde rij. Dit element vergelijken we met het gezochte element. Afhankelijk hiervan is het element gevonden, of moeten we links/rechts van het willekeurige element gaan zoeken vanwege het gesorteerd zijn van de rij. Als willekeurig element neemt men meestal het element dat in het midden van de rij staat, namelijk het element \(k = \lfloor (i + j)/2 \rfloor \).
\paragraph{Stelling 6.2.1} {\it De binaire zoekmethode heeft uitvoeringstijd \(T(n) = \Theta (logn) in het slechtste geval\)}
\paragraph{Bewijs.} De recurrente betrekking voor de uitvoeringstijd wordt gegeven door \(T(n) = T(n/2) + \Theta(1)\). Steunend op de masterstelling, is de oplossing hier van \(T(n) = \Theta(logn)\). De binaire zoekmethode is dus een logaritmisch algoritme.

\section{Het probleem van de maximale deelrijsom}
 \paragraph{Eigenschap 6.3.1.} {\it Voor willekeurige \( i \geq 0\), als \(a_i, ..., a_j\) de eerste deelrij is waarvoor de som negatief wordt, dan is voor elke \(i \leq p \leq j\) en elke \(q \geq p\), de deelrij \(a_p, ..., a_q\) ofwel geen maximale deelrij, ofwel een reeds geziene maximale deelrij.}
 \paragraph{Bewijs.} Voor p = i volgt het gestelde onmiddelijk uit bovenstaande observatie. Voor \(p > i\) is de beschouwde deelrij ofwel van de vorm \(a_i, ..., a_p, ..., a_j, ..., a_q\) ofwel van de vorm \(a_i, ..., a_p, ..., a_q, ..., a_j\). Aangezien j de eerste index is waarvoor de som negatief wordt, is de som van \(a_i, ..., a_{p-1}\) positief en is dus de som van \(a_p, ..., a_q\) kleiner dan of gelijk aan de som van \(a_i, ..., a_q\). In het eerste geval, als \(j < q\), weten we reeds dat de deelrij \(a_i, ..., a_q\) geen maximale deelrij is. Anders is  \(a_i, ..., a_q\) een reeds geziene deelrij met een grotere som.
 \paragraph{On-line algoritmen} Als de rij slechts eenmalig wordt doorlopen, het volstaat element per element te lezen, zonder de gegevens in het centrale geheugen in te lezen. Het heeft ook op elk moment de maximale deelrijsom van het reeds gelezen gedeelte van de inputrij.
 
 \section{Het probleem van het dichtste puntenpaar}

\chapter{Sorteeralgoritmen}
\section{Kwadratische sorteeralgoritmen}

\subsection{Sorteren door omwisseling {\bf BubbleSort}}
\paragraph{BubbleSort} Naast elkaar staande elementen worden vergeleken en verwisseld als ze niet in de goede volgorde staan. Het grootste element van de twee wordt naar achteren verschoven. Dit proces wordt herhaaldelijk uitgevoerd, tot n - 1 (telkens - 1, aangezien het laatste element van elke volledige iteratie op zijn juiste plaats staat). Dit wordt herhaald tot het voorlaatste element, want na n-1 fasen is de rij uiteindelijk gesorteerd.
\paragraph{Stelling 7.1.1} {\it BubbleSort heeft tijdscomplexiteit \(T(n) = \Theta(n^2)\)}
\paragraph{Bewijs} De probleemgrootte \(n\) is de dimensie van de rij. De essenti\"ele bewerkingen zijn vergelijkingen tussen rij-elementen en verwisselingen van rij-elementen. Het aantal vergelijkingen \(C(n)\) in het BubbleSort is hetzelfde voor alle mogelijke rijen van lengte n, namenlijk: \(C(n) = n(n-1)/2\). Het aantal verwisselingen \(S(n)\) is afhankelijk van de inputrij, en kan vari\"eren van \(S_b(n) = 0\) in het beste geval tot \(S_s(n) = n(n-1)/2\) in het slechtste geval. De totale complexiteit is dus \(T(n) = \Theta(n^2)\)

\subsection{Sorteren door selectie {\bf SelectionSort}}
\paragraph{SelectionSort} Is een rechtlijnig algoritme. Het grootste element inde rij wordt bepaald en achteraan geplaatst. Vervolgens wordt het tweede-grootste element bepaald en op de voorlaatste plaats gezet. Dit wordt herhaald op steeds kortere deelrijen, totdat de deelrij uiteindelijk maar \"e\"en element meer bevat.
\paragraph{Stelling 7.1.2}{\it SelectionSort heeft tijdscomplexiteit \(T(n) = \Theta(n^2)\)}
\paragraph{Bewijs} Het aantal vergelijkingen is \(C(n) = n(n-1)/2\), want in elke stap van de dubbele for-lus gebeurt een vergelijking. Het aantal verwisselingen is hoogstens \(S_s(n) = n-1\), hetgeen onmiddelijk duidelijk is uit de implementatie: de verwisseloperatie staat in de buitenste lus en kus hoogstens n-1 keer worden uitgevoerd. Het kan gebeuren dat er geen enkele verwisseling nodig is, nl. als de gegeven rij al gesorteerd is, m.a.w. \(S_b(n) = 0\). De totale tijdscomplexiteit is dus \(T(n) = \Theta(n^2)\)

\subsection{Sorteren door tussenvoegen {\bf InsertionSort}}
\paragraph{InsertionSort}In de begintoestand is het eerste element op zichzelf beschouwd, gesorteerd. In de eindtoestand zijn alle elementen, als groep beschouwd, gesorteerd. De basisbewerking van het algoritme is het rangschikken van de elementen op de posities 1 t.e.m. i, waarbij i een waarde tussen 2 en n heeft. Daarbij wordt verondersteld dat de elementen op posities 1 t.e.m. i-1 reeds gesorteerd zijn en wordt het element op positie i op de juiste plaats tussengevoegd. Het algoritme bestaat uit een aantal fasen waarbij i achtereenvolgens waarden van 2 t.e.m. n aanneemt.
\paragraph{Stelling 7.1.3}{\it InsertionSort heeft een slechtste-geval-uitvoeringstijd \(T_s(n) = \Theta(n^2)\) en een beste-geval-uitvoeringstijd van \(T_b(n) = \Theta(n)\).}
\paragraph{Bewijs}In het slechtste geval is het aantal stappen uitgevoerd door de dubbele for-lus gegeven door \(n(n-1)/2\). Elke stap komt overeen met een vergelijking en een verwisseling dus de uitvoeringstijd in het slechtste geval is \(\Theta(n^2)\).
Als echter de rij bij het begin van het algoritme reeds gesorteerd is, dan is de uitvoeringstijd \(\Theta(n)\), omdat de test bij het begin van de binnenste for-lus altijd faalt en de lus dus niet uitgevoerd wordt. Dit is ook het best mogelijke geval, want de buitenste lus heeft steeds n-1 stappen.

\subsubsection{Gemiddelde uitvoeringstijd}
\paragraph{Inversie}Een inversie van een rij \((a_1, ..., a_n)\) is elk paar \((i, j)\) waarvoor geldt dat \(i < j\) maar \(a_i > a_j\). {\it Het verwisselen van twee adjacente elementen die niet in de goede volgorde staan, vermindert het aantal inversies met precies \"e\"en. Een gesorteerde rij heeft geen inversies.}
\paragraph{Gemiddelde uitvoeringstijd} Om deze te berekenen gaan we uit van volgende veronderstellingen:
\begin{enumerate}
\item De rij bevat geen dubbels.
\item De rij beschouwen we als een permutatie van de eerste n natuurlijke getallen. We veronderstellen dat alle permutaties even waarschijnlijk zijn.
\end{enumerate}
\paragraph{Stelling 7.1.4}{\it Het gemiddelde aantal inversies in een rij van n verschillende getallen is gegeven door \(n(n-1)/4\)}
\paragraph{Bewijs}Voor een rij A noemen we \(A_r\) de rij in omgekeerde volgorde. Beschouw twee willekeurige getallen \((x,y)\) in de rij waarvoor \(y > x\). Dit paar correspondeert met een inversie in ofwel \(A\) ofwel \(A_r\). Het totale aantal dergelijke paren voor een rij \(A\) (en zijn omgekeerde \(A_r\)) is gegeven door \(n(n-1)/2\). Het aantal inversies in een gemiddelde rij is dus de helft hiervan, of \(n(n-1)/4\).
\paragraph{Stelling 7.1.5}{\it InsertionSort heeft gemiddelde uitvoeringstijd \(T_gg(n) = \Theta(n^2)\)}.
\paragraph{Bewijs}Merk op dat het aantal inversies in de te sorteren rij precies gelijk is aan het aantal keer dat in het algoritme de opdracht voor het verwisselen van \(a_j\) en \(a_j-1\) uitgevoerd wordt. \\ \\
Dus, als er k inversies zijn bij de start van het algoritme, dan moeten er k (impliciete) verwisselingen gebeuren. Aangezien er verder \(\Theta(n)\) ander werk nodig is in het algoritme, is de uitvoeringstijd van het sorteren door tussenvoegen gegeven door \(\Theta(k + n)\), met k het aantal inversies in de oorspronkelijke rij.\\ \\
Zoals in voorgaande stelling bewezen is het gemiddelde aantal inversies \(\Theta(n^2)\), waaruit onmiddelijk volgt dat sorteren door tussenvoegen kwadratisch is in het gemiddelde geval.

\subsubsection{Een ondergrens voor de uitvoeringstijd}
\paragraph{Bottleneck}Bij deze algoritmen is het feit dat dit algoritme slechts aangrenzende elementen met elkaar vergelijkt en/of verwisselt de bottleneck.
\paragraph{Stelling 7.1.6}{\it Om het even welk algoritme dat sorteert door het vergelijken en verwisselen van aangrenzende elementen, vereist gemiddeld \(\Omega(n^2) uitvoeringstijd\).}
\paragraph{Bewijs}Het gemiddelde aantal inversies bij het begin van het algoritme is \(n(n-1)/4\). Elke verwisseling vermindert het aantal inversies met precies \"e\"en, zodat dus \(\Omega(n^2)\) verwisselingen vereist zijn.

\section{MergeSort}
\paragraph{MergeSort} gebruikt recursie om te komen tot een effici\"ent sorteeralgoritme. De te sorteren rij wordt opgesplitst in twee deelrijen die half zo lang zijn als de oorspronkelijke rij. Meer plrecies, als n de lengte van de oorspronkelijke rij voorstelt, dan hebben de deelrijen resp. lengte \(\lfloor n/2 \rfloor\) en \(\lceil n/2 \rceil\). Deze twee deelrijen worden recursief gesorteerd en vervolgens samengevoegd tot \"e\"en enkele gesorteerde rij. Het samenvoegen van twee gesorteerde rijen wordt ook {\bf merge} genoemd, vandaar de naam.
\paragraph{Stelling 7.2.1}{\it MergeSort heeft tijdscomplexiteit \(T(n) = \Theta(nlogn)\)}.
\paragraph{Bewijs}MergeSort is een verdeel-en-heers algoritme, waarvan de uitvoeringstijd bepaald wordt door de recurrente betrekking \(T(n) = 2T(n/2) + \Theta(n)\). De oplossing hiervan is \(T(n) = \Theta(nlogn)\). Dit is zowel slechtste- als beste- en gemiddelde-geval-uitvoeringstijd, omdat het mergen altijd lineaire tijd kost.

\section{QuickSort}
\paragraph{QuickSort}Doorgaans is dit de beste keuze voor een intern sorteeralgoritme. Dit is een zeer snel sorteeralgoritme. De gemiddelde uitvoeringstijd is \(\Theta(nlogn)\) en de slechtst mogelijke uitvoeringstijd is \(\Theta(n^2)\), maar de kans dat dit slechtste geval zich voordoet kan zeer klein worden gemaakt.

\subsection{Het QuickSort-algoritme}
\paragraph{Partitioneren}Het partitioneert de te sorteren rij. Een willekeurig element s uit de rij wordt gekozen; dit element wordt de spil genoemd. Vervolgens wordt de rij opgesplitst in twee disjuncte deelrijen, nl. een deelrij L met elementen kleiner dan de spil en een deelrij R met elementen groter dan de spil. Deze twee deelrijen worden dan recursief gesorteerd, en aaneengeschakeld tot de uiteindelijke gesorteerde rij.
\paragraph{Stelling 7.3.1}{\it QuickSort sorteert de gegeven rij op correcte wijze.}
\paragraph{Bewijs}Daartoe steunen we op de volgende vaststellingen. Het principe van recursie garandeert dat de groep L van de kleine elementen en de groep R van de grote elementen na de recursieve oproepen gesorteerd zijn. De kenmerkende eigenschap van de partitionering garandeert dat het grootste element van L niet groter is dan de spil en dat het kleinste element van R niet kleiner is dan de spil. hieruit kunnen we besluiten dat de uiteindelijk gevormde rij correct gesorteerd is.

\subsection{Complexiteit van QuickSort}
\paragraph{Best mogelijke partitionering}Het best mogelijke geval voor QuickSort treedt op wanneer de spil de rij elementen opsplitst in twee deelrijen van gelijke grootte, en dat bij elke stap in de recursie. In dat geval: twee recursieve oproepen van halve probleemgrootte met lineaire overhead, hetgeen analoog is aan de situatie bij MergeSort, met als recurrente betrekking \(T(n) = 2T(n/2) + \Theta(n)\). De best mogelijke uitvoeringstijd van QuickSort is dus:\\
\(T_b(n) = \theta(nlogn)\).
\paragraph{Slechtst mogelijke partitionering}Deelproblemen van ongelijke grootte zijn ongunstig. Veronderstel: spil in elke stap het kleinste element van de deelrij, dan is de groep L van kleine elementen leeg terwijl de groep R van grote elementen de ganse deelrij behalve de spil bevat. De recurrente betrekking die de uitvoeringstijd in dit geval beschrijft, is \(T(n) = T(n-1) + \Theta(n)\). Gebruik maken van de iteratiemethode kunnen we hieruit afleiden dat de slechtst mogelijke uitvoeringstijd van QuickSort kwadratisch is:\\
\(T_s(n) = \theta(n^2)\).
\paragraph{Gebalanceerde partitionering en het gemiddelde geval} In het gemiddelde geval is de uitvoeringstijd \(\Theta(n log n)\).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               

\subsection{Keuze van de spil}
\paragraph{Aandachtspunt} Het vermijden van de slechtste uitvoeringstijd \(\Theta(n^2)\). Eerste of laatste element uit rij als spil wordt afgeraden, aangezien bij gesorteerde of omgekeerd gesorteerde rijen dit voor problemen zorgt. Het middelste element is een betere keuze, aangezien bij een gesorteerde rij, hier twee perfecte partities gevormd kunnen worden. Desondanks kan een kwadratische uitvoeringstijd nog steeds voorkomen, maar de kans om die te bekomen is zeer klein.
\paragraph{Mediaan-van-drie-partitionering}Deze methode probeert een beter dan gemiddeld goede spil te kiezen met behulp van de mediaan\footnote{De mediaan van een groep van n getallen is het \(\lceil n/2 \rceil\)-de kleinste getal.}. De beste keuze van de spil zou dus uiteraard de mediaan zijn, maar het berekenen van deze mediaan kost ook tijd en dit zou het algoritme te veel vertragen. We kunnen dit oplossen door de mediaan van een deelgroep te bepalen. In de praktijk gebruikt men doorgaans volgende drie elementen: het eerste element, het laatste element en het middelste element uit de rij.

\subsection{Het partitioneren van de rij}
\paragraph{Basispartitionering}Deze bestaat uit drie stappen. In de eerste stap wordt het spilelement achteraan geplaatst door het te verwisselen met het laatste element. (We veronderstellen voorlopig dat alle elementen verschillend zijn.) In de tweede stap worden alle elementen kleiner dan de spil naar het linkergedeelte van de rij gebracht, terwijl alle elementen groter dan de spil naar het rechtergedeelte worden gebracht. Dit gebeurt door van links naar rechts naar een element groter dan de spil te zoeken, via een huidige positie links die start bij het begin. Analoog zoeken we van rechts naar links naar een element kleiner dan de spil, via een huidige positie rechts. Deze twee elementen worden van plaats verwisseld. Dit wordt herhaalt tot wanneer de twee huidige posities links en rechts mekaar passeren in de rij. De derde stap bestaat uit het verwisselen van de spil met het eerste element groter dan de spil.
\paragraph{Bij sleutels gelijk aan de spil?} Beide links en rechts moeten stoppen wanneer een sleutel gelijk aan de spil ontmoet wordt. 
\paragraph{Mediaal-van-drie-partitionering}Het is het eenvoudigste manier om het eerste het middelste en laatste element te sorteren. Merk op: eerste element is \(\leq\) spil en laatste element is \(\geq\) spil, waardoor we de spil naar het voorlaatste element kunnen verplaatsen en links kan starten bij het tweede element en rechts bij het derde laatste element van de deelrij.

\section{Lineaire sorteeralgoritmen}

\subsection{CountingSort}
\paragraph{CountingSort} Dit algoritme kan worden gebruikt voor het sorteren van een rij \((a_1, ..., a_n)\), waarbij de sleutels \(a_i\) gehele getallen zijn uit het interval \([0,k]\), voor een niet te grote waarde van k. Om de rij te sorteren telt het algoritme hoeveel keer elke waarde voorkomt; uit deze informatie kan de positie van elke sleutel in de gesorteerde rij worden berekend en kan de rij worden gesorteerd. Dit is een stabiel\footnote{Een sorteeralgoritme wordt stabiel genoemd als elementen die dezelfde sleutel hebben (de sleutel is dat kenmerk van een element dat wordt vergeleken met de sleutel van een ander element om de volgorde te bepalen) niet bij het sorteren ten opzichte van elkaar van volgorde veranderen. {\it Bron: Wikipedia}} sorteeralgoritme.
\paragraph{Stelling 7.4.1}{\it De uitvoeringstijd van CountingSort is \(T(n) = \Theta(n)\) als \(k = O(n)\).}
\paragraph{Bewijs}Elke lus in het algoritme is ofwel \(\Theta(n)\) ofwel \(\Theta(k)\). De uitvoeringstijd van het algoritme is dus \(T(n) = \Theta(n + k)\). Wanneer \(k \leq n\), of meer algemeen, wanneer k een functie van n is waarvoor \(k = O(n)\), dan wordt k verwaarloosbaar tegenover n en krijgen we dus een lineaire uitvoeringstijd \(T(n) = \Theta(n)\) voor het algoritme.

\subsection{RadixSort}
\paragraph{RadixSort}Dit is een algoritme dat kan worden gebruikt voor het sorteren van een rij  \((a_1, ..., a_n)\) van positieve gehele getallen, die een beperkt aantal cijfers hebben.Om deze rij te sorteren wordt eerst een stabiel sorteeralgoritme gebruikt om de getallen te sorteren op hun laatste cijfer, vervolgens op hun voorlaatste cijfer, enzovoort, tot uiteindelijk gesorteerd wordt op het eerste cijfer.
\paragraph{Stelling 7.4.2}{\it RadixSort sorteert de gegeven rij op correcte manier.}
\paragraph{Bewijs} Zij m het aantal cijfers in de getallen. Zij x een sleutel uit de te sorteren rij. We bewijzen dat, wanneer het algoritme stopt, elke sleutel met waarde groter dan x in de rij na x komt, waaruit volgt dat de rij gesorteerd is. \\
Beschouw de decimale voorstelling van  \(x = x_{m-1}10^{m-1} + ... + 10x_1 + x_0\) en van een element \(y = y_{m-1}10^{m-1} + ... + 10y_1 + y_0\) uit de rij, en onderstel dat \(y > x\). Zij \(l\) de grootste index waarvoor \(x_l \neq y_l\). Aangezien \(y > x\) is dus \(y_l > x_l\). Wanneer CountingSort sorteert met het cijfer corresponderend met \(10^l\) als sleutel, wordt y dus achter x geplaatst. Bij volgende uitvoeringen van CountingSort is telkens \(x_i = y_i\) \((i > l)\) en aangezien CountingSort stabiel is, blijft y in de rij achter x geplaatst.
\paragraph{Stelling 7.4.3}{\it De uitvoeringstijd van RadixSort is \(T(n) = \Theta(n)\), wanneer het aantal cijfers m begrensd is door een constante.}
\paragraph{Bewijs}De uitvoeringstijd van het sorteren in elke stap van de for-lus is \(\Theta(n + 9)\), dus \(\Theta(n)\). Aangezien de for-lus m stappen heeft, is de totale complexiteit dus \(T(n) = \Theta(mn)\). Wanneer we veronderstellen dat \(m = \Theta(1)\), dan is de uitvoeringstijd van RadixSort \(T(n) = \Theta(n)\).

\chapter{Grafen}

\section{Grafen}

\subsection{Wat is een graaf}
\paragraph{Grafen}Grafen bestaan bestaan uit {\bf toppen} en {\bf bogen} en een {\bf incidentierelatie} hiertussen. De toppen en bogen kunnen bijkomende attributen hebben zoals kleur of gewicht.
\paragraph{Grafen, toppen en bogen}Een graaf G = (V(G), E(G)) bestaat uit een eindige verzameling V(G) van objecten, toppen genoemd, en een verzameling E(G) van paren van elementen uit V(G), bogen genoemd. V(G) noemen we de {\bf toppenverzameling} van G genoemd en E(G) de {\bf bogenverzameling}. Elke boog is geassocieerd met een verzameling van twee toppen, {\bf eindpunten} genaamd. Een boog {\bf verbindt} zijn eindpunten. Het aantal toppen in G noemen we de {\bf orde} van de graaf en het aantal bogen noemen we de {\bf grootte}  \(\approx\) een (n, m)-graaf.
\paragraph{Stelling 8.1.1}{\it Wanneer G een (n,m)-graaf is, dan geldt dat \(m \leq n(n-1)/2 \).}
\paragraph{Bewijs}Dit volgt onmiddelijk uit het feit dat er \(n(n-1)/2\) mogelijke paren van elementen van V(G) zijn.
\paragraph{Adjacent}Adjacente toppen zijn twee toppen, verbonden door een boog. We noteren: u \(\sim\) v. Adjacente bogen zijn twee bogen die een eindpunt gemeen hebben. Als een top v een eindpunt is van een boog e, dan noemen we v {\bf incident} met e en vice versa.
\paragraph{Dichte graaf}Als de meeste bogen aanwezig zijn, dan is \(|E|\) = \(\Theta(|V|^2)\), dan spreken we van een dichte graaf. In de meeste gevallen is de graaf eerder {\bf ijl}, dan is \(|E|\) = \(\Theta(|V|)\) of slechts iets meer.
\paragraph{Simpele grafen, multigrafen en pseudografen}Multigraaf: toppen kunnen door meer dan \"e\"en boog verbonden worden. We noemen deze twee of meer bogen, {\bf parallelle bogen}. Een collectie van parallelle bogen noemen we een {\bf multiboog}. {\bf Zelflus}: top die met zichzelf is verbonden. Indien een boog geen zelflus is, dan wordt die een {\bf eigenlijke boog} genoemd. Als we zelflussen en multibogen toelaten bekomen we een {\bf pseudograaf}. Een graaf zonder deze bogen noemen we een {\bf simpele graaf}.
\paragraph{Gerichte grafen en gewogen grafen}Een {\bf gerichte boog of pijl} is een boog waarvan een van de eindpunten als {\bf kop} wordt aangeduid, en de andere als {\bf staart}. De pijl is gericht van zijn kop naar zijn staart. Multipijl: verzameling van twee of meer pijlen die dezelfde kop en dezelfde staart hebben. Een {\bf gerichte graaf} is een graaf waarvan alle bogen gericht zijn. Een {\bf gedeeltelijk gerichte graaf} bevat gerichte en ongerichte bogen. Een {\bf onderliggende graaf} van een (gedeeltelijk) gerichte graaf is de graaf die we bekomen door de richtingen op de bogen te verwijderen. \\ Anders kan het ook nuttig zijn om een attribuut aan de bogen van een graaf te hechten, {\it Bijvoorbeeld de afstand tussen twee steden}. Een {\bf gewogen graaf} is een graaf waarbij elke boog een getal toegekend is. We noemen dat getal {\bf het gewicht}.

\subsection{De graad van een top}
\paragraph{Nabuurschap}Het nabuurschap van een top v van een graaf G wordt gedefinieerd als \(N_G(v) = \{u \in V(G) | vu \in E(G)\}\). De {\bf graad} \(deg_G(v) = |N_g(v)|\), het aantal toppen adjacent met v, of aantal bogen incident met v. Een top met graad 0 is een {\bf ge\"isoleerde top}. Een top met graad 1 is een {\bf eindtop}. Een {\bf even top} is een top met een even graad en idem voor een {\bf oneven top}. De {\bf gradenrij} van een graaf G, is de rij gevormd door de graden van de toppen in stijgende volgorde te rangschikken. De kleinste graad is de {\bf minimumgraad} en doorgaans genoteerd als \(\delta(G)\). De grootste waarde is de {\bf maximumgraad} van G en genoteerd als \(\Delta(G)\).
\paragraph{Stelling 8.1.2}{\it Een graaf G van orde \(n > 1\) heeft minstens \'e\'en paar toppen waarvan de graden gelijk zijn.}
\paragraph{Bewijs}Het is gemakkelijk in te zien dat voor een graaf G van orde n en een top v van G geldt dat \(0 \leq deg(v) \leq n-1\). Er zijn dus n mogelijke waarden voor de graad van een top, nl. 0, ..., n-1. Er kan echter niet zowel een top van graad 0 als een top van graad n-1 zijn, omdat de aanwezigheid van een top van graad 0 impliceert dat elk van de n-1 andere toppen met hoogstens n-2 toppen adjacent kan zijn. De n toppen van G kunnen dus hoogstens n-1 mogelijke waarden voor hun graad realiseren. Gebruik makend van het {\it pigeonhole principle} volgt hieruit dat minstens twee van de n toppen dezelfde graad hebben.
\paragraph{Stelling 8.1.3 (Euler)}{\it Zij G een graaf met orde n en een grootte m, en zij \(V(G) = \{v_1, ..., v_n\}\). Dan geldt dat \(\Sigma_{i=1}^n deg(v_i) = 2m\).}
\paragraph{Bewijs}Wanneer de som van de graden van de toppen berekend wordt, wordt elke boog tweemaal meegerekend, nl. eenmaal voor elk van zijn twee incidente toppen.
\paragraph{Ingraad, Uitgraad}De ingraad van een top v in een gerichte graaf G is het aantal pijlen dat naar v gericht is. De uitgraad van v is het aantal pijlen dat vanuit v gericht is.
\paragraph{Stelling 8.1.4}{\it In een gerichte graaf G zijn de som van de ingraden en de som van de uitgraden allebei gelijk aan het aantal bogen van G}.
\paragraph{Bewijs}Elke gerichte boog e draagt \'e\'en bij aan de ingraad van de staart van e en \'e\'en aan de uitgraad van de kop van e.

\subsection{Paden en samenhangendheid}
\paragraph{Wandeling}Een wandeling van top \(v_0\) naar top \(v_l\) is een rij met afwisselend toppen en bogen, van de vorm \(W = (v_0, e_1, v_1, e_2, ..., v_{l-1}, e_l,v_l)\), zondanig dat de eindpunten van elke boog \(e_i\) uit de rij \(v_{i-1}\) en \(v_i\) zijn, voor elke \(i = 1,...,l\). In een gerichte graaf is dit een {\bf gerichte wandeling} van \(v_0\) naar \(v_l\), en een rij met afwisselend toppen en pijlen. Een (gerichte) wandeling van een top x naar een top y wordt ook een (gerichte) x-y-wandeling genoemd. Als \(x = y\), dan noemen we dit een {\bf gesloten}, anders een {\bf open} wandeling.
\paragraph{Spoor}Een spoor is een wandeling waarin geen herhalende bogen voorkomen. Een gesloten spoor noemen we een {\bf circuit}. 
\paragraph{Pad} Een pad is een wandeling waarin geen herhalende toppen voorkomen, behalve evt. begin en eindpunt. Een gesloten pad noemen we een {\bf cykel}.
\paragraph{Gericht} We hebben eveneens een gericht spoor en een gericht pad.
\paragraph{Lengte/Taille}Lengte van een wandeling, spoor of pad is het aantal bogen hierin. De taille van een graaf G is de lengte van de kortste cykel in G.
\paragraph{Euleriaans spoor}Dit is een open spoor dat elke boog van G bevat, een {\bf euleriaans circuit} is een gesloten spoor dat elke boog van G bevat. Een {\bf euleriaanse graaf} is een graaf die een euleriaans circuit bevat.
\paragraph{Hamiltoniaans pad}Is een pad dat elke top van G aandoet. Een {\bf hamiltoniaanse cykel} is een cykel die elke top van G aandoet. Een {\bf hamiltoniaanse graaf} is een graaf die een hamiltoniaanse cykel bevat.
\paragraph{}Een top v van een graaf G is {\bf bereikbaar vanuit} een top u van G als er een wandeling van u naar v is. Een graaf G is {\bf Ssamenhangend} als er voor elk paar toppen u en v een wandeling van u naar v is, m.a.w. als elke top bereikbaar is vanuit elke andere top.
\paragraph{}Twee toppen u en v in een gerichte graaf D zijn {\bf wederzijds bereikbaar} als D een gerichte u-v-wandeling een een gerichte v-u-wandeling bevat. Een gerichte graaf is {\bf sterk samengangend} als elke twee toppen ervan wederzijds bereikbaar zijn. Een gerichte graaf is {\bf zwak samenhangend} als de onderliggende graaf samenhangend is.

\subsection{Bomen en wouden}
\paragraph{Acyclische graaf} Dit is een graaf waarin geen cykels optreden. We noemen zo'n graaf een {\bf woud}. Een {\bf boom} is een samenhangende graaf die geen cykels bevat. Een {\bf gerichte acyclische graaf, DAG} is een gerichte graaf waarin geen gerichte cykels optreden.

\subsection{Deelgrafen}
\paragraph{Deelgraaf}Is een graaf H van een graaf G als \(V(H) \subseteq V(G)\) en \(E(H) \subseteq E(G)\). Een {\bf echte deelgraaf} H van een graaf G is een deelgraaf waarvoor de toppenverzameling V(H) een echte deelverzamelig is van V(G). Het {\bf gewicht} w(H) van een deelgraaf H van een gewogen graaf G is de som van de gewichten van de bogen van H.
\paragraph{}Zij S een niet-ledige deelverzameling van V(G). De {\bf deelgraaf ge\"induceerd door } S, genoteerd als \(<S>\), is de maximale deelgraaf van G met toppenverzameling S, m.a.w. \(<S>\) bevat precies die bogen van G die toppen van S verbinden. Het is een {\bf top-ge\"induceerde deelgraaf, of ge\"induceerde deelgraaf}, als H : \(<S>\) voor zekere niet-ledige deelverzameling S van de toppen van G.
\paragraph{}Een {\bf deelgraaf ge\"induceerd door} een niet-ledige deelverzameling X van bogen van G, genoteerd als \(<X>\), is de minimale deelgraaf van G met bogenverzameling X, m.a.w. \(<X>\) bestaat uit die toppen van G die incident zijn met ten minste \'e\'en boog van X. een deelgraaf H van een graaf G is een {\bf boogge\"induceerde deelgraaf} als H = \(<X>\) voor zekere niet-ledige verzameling X van bogen van G.
\paragraph{Opspannend}Een deelgraaf H van een graaf G wordt een {\bf opspannende deelgraaf} van G genoemd als V(H) = V(G). Een {\bf opspannend woud} van een graaf G is een opspannende deelgraaf van G die een woud is. Een {\bf opspannende boom} van een graaf G is een opspannende deelgraaf van G die een boom is.
\paragraph{Stelling 8.1.5}{\it Een graaf is samenhangend als en slechts als hij een opspannende boom bevat.}
\paragraph{Bewijs}Veronderstel dat G een opspannende boom T bevat. Per definitie is T samenhangend, dus is er een pad tussen elk paar toppen van T, en dus ook tussen elk paar toppen van G.\\ \\
Veronderstel dat G samenhangend is. Als G geen boom is, bevat G minstens \'e\'en cykel.  Wanneer we uit dergelijke cykel een boog verwijderen, blijft de graaf nog steeds samenhangend. Op die manier kunnen we uit elke cykel een boog verwijderen tot we een acyclische graaf bekomen. Deze is nog steeds samenhangend en is dus een opspannende boom van de oorspronkelijke graaf.
\paragraph{Component}De component van een graaf G is een maximale samenhangende deelgraaf van G.

\subsection{Scharnierpunten en bruggen}
\paragraph{Schrapping}Zij G een graaf. De schrapping van een echte deelverzameling S van toppen uit G is de deelgraaf die bestaat uit de toppen van G die niet tot S behoren, en de bogen van G die niet incident zijn met een top in S. We noteren deze deelgraaf als G - S. Als S bestaat uit \'e\'en enkele top v, dan noteren we G -v.\\ De schrapping van een verzameling X van bogen van een graaf G, genoteerd als G-X, is de opspannende deelgraaf van G die bekomen wordt door het verwijderen van de bogen van X uit E(G).
\paragraph{Toevoegen}We kunnen ook paren van niet-adjacente toppen van een graaf G toevoegen aan de graaf. 
\paragraph{Toppensnede}Zij G een samenhangende graaf, een {\bf toppensnede} in G is dan een toppenverzameling S zodanig dat G-S niet samenhangend is. Een {\bf scharnierpunt} is een toppensnede bestaande uit één enkele top.
\paragraph{Bogensnede}Een bogensnede in G is een verzameling bogen X, zodanig dat G - X niet samenhangend is, en G - X' wel samenhangend is, voor elke \(X' \subset X\). Een bogensnede X partitioneert de toppen van G in twee disjuncte verzamelingen \(V_1, V_2\), zodanig dat elke boog uit X een eindtop in \(V_1\) en een eindtop in \(V_2\) heeft. Een {\bf brug} is een bogensnede bestaande uit \'e\'en enkele boog.
\paragraph{Stelling 8.1.6}{\it Een boog e van een samenhangende graaf G is een brug van G als en slechts als e niet op een cykel in G ligt.}
\paragraph{Bewijs}Is de boog e een brug, dan moeten zijn toppen noodzakelijkerwijs in verschillende componenten liggen als we e wegnemen uit G. Dit is duidelijk niet het geval als e op een cykel ligt. Omgekeerd, onderstel nu dat de boog e geen brug is. Nemen we e weg, dan bekomen we een samenhangende graaf. In het bijzonder zijn de eindtoppen v en w van e verbonden met elkaar door een pad dat de boog e niet bevat. Toevoegen van e aan het pad geeft ons een cykel die e bevat.

\subsection{Speciale families van grafen}
\paragraph{Complete graaf}Dit is een graaf waarbij elk paar toppen verbonden is door een boog. Een complete graaf met n toppen noteren we als \(K_n\).
\paragraph{Bipartiete graaf}Dit is een graaf waarvan de toppenverzameling V kan worden opgesplitst in twee deelverzamelingen \(V_1\) en \(V_2\) zodanig dat elke boog van G een eindpunt in \(V_1\) en een eindpunt in \(V_2\) heeft.  Het paar (\(V_1, V_2\)) wordt de {\bf bipartitie} van G genoemd, en \(V_1, V_2\) zijn de {\bf bipartitieverzamelingen}
\paragraph{Complete bipartiete graaf}Dit is een bipartiete graaf waarbij elke top van de ene bipartitieverzameling verbonden is met elke top van de andere bipartitieverzameling. Zo'n graaf met p toppen en q toppen in respectievelijk \(V_1, V_2\) noteren we als \(K_{p,q}\).
\paragraph{Regulier}Een graaf G is r-regulier of regulier van graad r, als elke top van G graad r heeft, \(r > 0\). 
\paragraph{Padgraaf}Een padgraaf \(P_n\) met n toppen is een samenhangende graaf met \(|V(P_n)| = |E(P_n)| + 1\), die getekend kan worden zodanig dat al zijn toppen en bogen op \'e\'en enkele rechte lijk liggen.
\paragraph{Cykelgraaf}Is een samenhangende graaf \(C_n\) met n toppen en met \(|V(C_n)| = |E(C_n)|\) die zodanig kan worden getekend dat al zijn toppen en bogen op een cirkel liggen.
\paragraph{Hyperkubus}Is een d-reguliere graaf \(Q_d\), waarvan de toppenverzameling bestaat uit de bitstrings van lengte d, zodanig dat er een boog is tussen twee toppen als en slechts als ze in slechts \'e\'en bit verschillen.

\section{Voorstellen van grafen}

\subsection{Adjacentiematrixvoorstelling}
\paragraph{Adjacentiematrix}Zij \(G = (V,E)\) een ongewogen, ongerichte graaf met toppenverzameling \(V = \{v_1, v_2, ..., v_n\}\). De adjacentiematrix \(A = [a_{ij}]\) van G is de n x n matrix gedefinieerd door:\\
\(a_{ij} =  \begin{cases} 1, als\ v_iv_j \in E, \\ 0, anders. \end{cases} \)
\paragraph{Gerichte grafen}Eerder genoemd kostenmatrix. Hierin wordt het gewicht van de boog \(v_iv_j\) weergegeven op positie \(a_{ij}\).
\paragraph{Voor multigrafen en pseudografen} \(a_{ij} =  \begin{cases} \mbox{het aantal bogen tussen } v_i, v_j, als\ v_i \neq v_j, \\ \mbox{het aantal zelflussen in } v_i, als\ v_i = v_j. \end{cases} \)
\paragraph{Geheugen}Deze matrix neemt \(n^2\) geheugen in, wat soms een verspilling is, vandaar volgende voorstelling.

\subsection{Adjacentielijstvoorstelling}
\paragraph{Adjacentielijstvoorstelling}Associeert met elke top van G een lijst van toppen die ermee adjacent zijn. {\it Bijvoorbeeld bij een gerichte graaf: lijst met uitburen of bij gewogen graaf gewicht ook bijhouden.}
\paragraph{Geheugen}Voor deze voorstelling zijn er \(\Theta(n + m)\) geheugenplaatsen nodig, met n toppen en m bogen van een graaf G.

\section{Euleriaanse grafen}
\subsection{Stadswandeling in K\"oningsberg}
\subsection{Karakterisatie van euleriaanse grafen}
\paragraph{Stelling 8.3.1}{\it Een samenhangende multigraaf G is euleriaans als en slechts als de graad van elke top even is.}
\paragraph{Bewijs}Veronderstel dat G een euleriaanse multigraaf is. Dan bevat G een euleriaans circuit C, dat begint en eindigt in een top v. We tonen aan dat elke top van G even graad heeft. Beschouw eerst een top \(u \neq v\). aangezien u noch de eerste noch de laatste top van C is, wordt de top u bij ieder voorkomen in C binnengekomen door een bepaalde boog en verlaten door een andere boog. M.a.w. ieder voorkomen van u in C draagt precies 2 bij tot de graad van u, zodat u even graad heeft. Voor de top v draagt elk van de voorkomens aan het begin en het einde van het circuit C precies 1 bij tot de graad van v, zodat dus ook de top v even graad heeft.\\ \\
Omgekeerd, veronderstel dat elke top van G even graad heeft. We tonen aan dat G euleriaans is door een euleriaans circuit te construeren. Selecteer een top v van G en start een spoor T in v. We bouwen dit spoor zo ver mogelijk op, totdat we een top w bereiken zodanig dat de enige bogen incident met w reeds tot T behoren. We beweren dat \(w = v\). Veronderstel dat \(w \neq v\). Iedere keer als w optreedt in T v\'o\'or de laatste keer wordt \'e\'en boog gebruikt om w binnen te komen en wordt een andere boog gebruikt om w te verlaten. De voorkomens van w in T v\'o\'or de laatste keer komen dus overeen met een even aantal bogen incident met w. Wanneer w echter voor de laatste keer in T optreedt, wordt slechts \'e\'en boog incident met w gebruikt. M.a.w. het spoor T bevat een oneven aantal bogen incident met w. Aangezien w even graad heeft, moet er dus minstens \'e\'en boog incident met w in T voorkomen. Dus, de bewering dat w = v is correct, en T is dus eigenlijk een circuit. Als T alle bogen van G bevat, dan is T een euleriaans circuit en is G dus en euleriaanse graaf.\\ \\
Veronderstel nu dat T niet alle bogen van G bevat. Aangezien G samenhangend is, bestaat er een top u in T die incident is met bogen die niet tot T behoren. Beschouw de multigraaf H bekomen door de bogen van T uit G te verwijderen. Aangezien T niet alle bogen van G bevat , is de multigraaf H niet-leeg. Bovendien is elke top van T incident met een even aantal bogen van T, zodat elke top in H ook even graad heeft. Zij \(H_1\) de component van H die de top u bevat. Wanneer we een spoor T' in u beginnen, en dit zo ver mogelijk opbouwen, dan bekomen we net zoals voordien dat T' eindigt in u, zodat T' een circuit is. Wanneer we het circuit T' tussenvoegen in T op een plaats waar u voorkomt, dan bekomen we een circuit \(T_1\) dat begint en eindigt in v, en dat meer bogen dan T bevat.\\ \\
Als \(T_1\) alle bogen van G bevat, dan is \(T_1\) een euleriaans circuit en is G een euleriaanse multigraaf. In het andere geval, wanneer \(T_1\) niet alle bogen van T bevat, dan herhalen we bovenstaande procedure totdat we een euleriaans circuit bekomen.
\paragraph{Stelling 8.3.2}{\it Een samenhangende multigraaf G bevat een euleriaans spoor als en slechts als G precies twee toppen met oneven graad heeft. Bovendien begint het euleriaans spoor dan in een van de toppen met oneven graad en eindigt het in de andere top met oneven graad.}
\paragraph{Chinese postbodeprobleem}De {\bf kost} is het totale extra bogen die worden toegevoegd in een graaf om een euleriaans te krijgen.

\section{Hamiltoniaanse grafen en TSP}

\subsection{Hamiltoniaanse grafen}
\paragraph{Onhandelbaar}Het bepalen van een hamiltoniaanse cykel in een algemene graaf is een onhandelbaar probleem. Er is dus geen goed algoritme voor gekend.

\subsection{Handelreizigersprobleem (TSP)}
\paragraph{}Zoekt een hamiltoniaanse cykel in een graaf waarvoor de totale boogkost minimaal is.

\subsection{Algoritmen voor TSP}
\paragraph{}Vereist berekenen van het gewicht van \((n-1)!/2\) hamiltoniaanse cykels van G, als volgt. Een hamiltoniaanse cykel kan worden voorgesteld als een opeenvolging van toppen, startend met top 1, die alle toppen bevat. Een oplossing voor het handelsreizigersprobleem wordt bekomen door alle permutaties van dergelijke opeenvolgingen van toppen te genereren, de lengte van de corresponderende cykels te berekenen en de kortste hiervan te bepalen.

\section{Gerichte acyclische grafen}

\subsection{Topologisch sorteren van een DAG}
\paragraph{Topologische ordening}Een topologische ordeningen in een DAG is een ordening van de toppen van een gerichte acyclische graaf zodanig dat, als er een pad is van u naar v, dan v in de ordening n\'a u komt. Het {\bf topologisch sorteren} is het bepalen van een topologische ordening.




\paragraph{}
\end{document}